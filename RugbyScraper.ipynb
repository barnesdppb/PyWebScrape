{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rugby/report?gameId=290778&league=242041\n"
     ]
    }
   ],
   "source": [
    "# TEST - go to the scrum.com fixtures page and extract the results links. Info is in JSON format, so pull that \n",
    "# from the HTML then parse\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import datetime\n",
    "import random\n",
    "import re\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "\n",
    "# This works for pages that have a single match, probably not for multiple matches\n",
    "date = '20170302'\n",
    "def getLinks (articleUrl):\n",
    "    html = urlopen(\"http://www.espn.co.uk/rugby/fixtures/_/date/\" + articleUrl)\n",
    "    bsObj = bs(html, \"lxml\")\n",
    "    return bsObj.find(\"section\", {\"id\":\"pane-main\"}).findAll(\"script\", {\"type\":\"text/javascript\"})\n",
    "    return bsObj.find(\"section\", {\"id\":\"pane-main\"})\n",
    "\n",
    "\n",
    "tst = getLinks(date)\n",
    "for t in tst:\n",
    "    json_text = re.search(r'^\\s*window\\.__INITIAL_STATE__\\s*=\\s*({.*?})\\s*;\\s*$',\n",
    "                      t.string, flags=re.DOTALL | re.MULTILINE).group(1)\n",
    "\n",
    "json_out = json.loads(json_text)\n",
    "match = json_out['schedule']['groups'][0]['complete'][0]['result']['href']\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/rugby/report?gameId=290778&league=242041'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_out['schedule']['groups'][0]['complete'][0]['result']['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing a day with multiple matches\n",
    "# TEST - go to the scrum.com fixtures page and extract the results links. Info is in JSON format, so pull that \n",
    "# from the HTML then parse\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import datetime\n",
    "import random\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "\n",
    "# This works for pages that have a single match, probably not for multiple matches\n",
    "date = '20170304'\n",
    "def getLinks (articleUrl):\n",
    "    html = urlopen(\"http://www.espn.co.uk/rugby/fixtures/_/date/\" + articleUrl)\n",
    "    bsObj = bs(html, \"lxml\")\n",
    "    return bsObj.find(\"section\", {\"id\":\"pane-main\"}).findAll(\"script\", {\"type\":\"text/javascript\"})\n",
    "\n",
    "tst = getLinks(date)\n",
    "for t in tst:\n",
    "    json_text = re.search(r'^\\s*window\\.__INITIAL_STATE__\\s*=\\s*({.*?})\\s*;\\s*$',\n",
    "                      t.string, flags=re.DOTALL | re.MULTILINE).group(1)\n",
    "\n",
    "json_out = json.loads(json_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rugby/report?gameId=290088&league=267979\n",
      "/rugby/report?gameId=290089&league=267979\n",
      "/rugby/match?gameId=290364&league=270559\n",
      "/rugby/match?gameId=290363&league=270559\n",
      "/rugby/match?gameId=290366&league=270559\n",
      "/rugby/match?gameId=290365&league=270559\n",
      "/rugby/report?gameId=290524&league=270557\n",
      "/rugby/report?gameId=290520&league=270557\n",
      "/rugby/report?gameId=290523&league=270557\n",
      "/rugby/report?gameId=290786&league=242041\n",
      "/rugby/report?gameId=290785&league=242041\n",
      "/rugby/report?gameId=290784&league=242041\n",
      "/rugby/match?gameId=290783&league=242041\n",
      "/rugby/report?gameId=290782&league=242041\n",
      "/rugby/report?gameId=290781&league=242041\n"
     ]
    }
   ],
   "source": [
    "# Structure like so: json_out['schedule']['groups'][m]['complete'][n]['result']['href']\n",
    "# m is the league in question and n is the game within that league, iterate through both for all results\n",
    "\n",
    "json_match = json_out['schedule']['groups']\n",
    "matches = []\n",
    "\n",
    "for m in json_match:\n",
    "    for c in m['complete']:\n",
    "        matches.append(c['result']['href'])\n",
    "        \n",
    "for m in matches:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just pick a single match link to look at\n",
    "match_link = matches[0]\n",
    "\n",
    "# New function, very similar to the above, to extract the stats links\n",
    "def getStatsLinks (articleUrl):\n",
    "    html = urlopen(\"http://www.espn.co.uk\" + articleUrl)\n",
    "    bsObj = bs(html, \"lxml\")\n",
    "    return bsObj.find(\"section\", {\"id\":\"pane-main\"}).findAll(\"script\", {\"type\":\"text/javascript\"})\n",
    "\n",
    "# Saved to list this time but still only one element\n",
    "tst = getStatsLinks(match_link)\n",
    "json_out = []\n",
    "for t in tst:\n",
    "    json_text = re.search(r'^\\s*window\\.__INITIAL_STATE__\\s*=\\s*({.*?})\\s*;\\s*$',\n",
    "                      t.string, flags=re.DOTALL | re.MULTILINE).group(1)\n",
    "    json_out.append(json.loads(json_text))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are tall the match related links, we are interested in the match\n",
    "# and player stats, as well as lineups and possibly table\n",
    "json_out[0]['gamePackage']['links']\n",
    "\n",
    "for j in json_out[0]['gamePackage']['links']:\n",
    "    if j['pageType'] == 'matchstats':\n",
    "        match_s = j['href']\n",
    "    elif j['pageType'] == 'playerstats':\n",
    "        player_s = j['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getStats(statsUrl):\n",
    "    html = urlopen(\"http://www.espn.co.uk\" + statsUrl)\n",
    "    bsObj = bs(html, \"lxml\")  \n",
    "    return bsObj.find(\"section\", {\"id\":\"pane-main\"}).findAll(\"script\", {\"type\":\"text/javascript\"})\n",
    "\n",
    "p_stats = getStats(player_s)\n",
    "\n",
    "# json.loads turns the JSON object into a Python dict - so it's now a dict and follows those rules \n",
    "stat_out = []\n",
    "# This is length 1 but has to be done as if we don't iterate though it's of type \"ResultsSet\"\n",
    "# which we can do do any operations on. So after this it will take the __INITIAL_STATE__ variable,\n",
    "# grab the JSON object and make it into a Python dict\n",
    "for p in p_stats:\n",
    "    json_text = re.search(r'^\\s*window\\.__INITIAL_STATE__\\s*=\\s*({.*?})\\s*;\\s*$',\n",
    "                      t.string, flags=re.DOTALL | re.MULTILINE).group(1)\n",
    "    stat_out.append(json.loads(json_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for s in stat_out[0]:\n",
    "#    for i in stat_out[0][s]:\n",
    "#        print(s, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'captain': False,\n",
      " 'cleanbreaks': {'name': 'Clean Breaks', 'value': '0'},\n",
      " 'conversiongoals': {'name': 'Conversion Goals', 'value': '0'},\n",
      " 'defendersbeaten': {'name': 'Defenders Beaten', 'value': '0'},\n",
      " 'dropgoalsconverted': {'name': 'Drop Goals Converted', 'value': '0'},\n",
      " 'eventTimes': {'3': [\"41'+3\"]},\n",
      " 'homeAway': 'home',\n",
      " 'id': '82104',\n",
      " 'kicks': {'name': 'Kicks', 'value': '2'},\n",
      " 'lineoutswon': {'name': 'Lineouts Won', 'value': '0'},\n",
      " 'lineoutwonsteal': {'name': 'Lineout Won Steal', 'value': '0'},\n",
      " 'metres': {'name': 'Metres Run', 'value': '15'},\n",
      " 'missedtackles': {'name': 'Missed Tackles', 'value': '1'},\n",
      " 'name': 'Tom Homer',\n",
      " 'number': '15',\n",
      " 'offload': {'name': 'Offload', 'value': '0'},\n",
      " 'onPitch': False,\n",
      " 'passes': {'name': 'Passes', 'value': '6'},\n",
      " 'penalties': {'name': 'penalties', 'value': 1},\n",
      " 'penaltiesconceded': {'name': 'Penalties Conceded', 'value': '0'},\n",
      " 'penaltygoals': {'name': 'Penalty Goals', 'value': '1'},\n",
      " 'points': {'name': 'Points', 'value': '3'},\n",
      " 'position': 'FB',\n",
      " 'redcards': {'name': 'Red Cards', 'value': '0'},\n",
      " 'runs': {'name': 'Runs', 'value': '6'},\n",
      " 'subToolTip': '',\n",
      " 'subbed': False,\n",
      " 'tackles': {'name': 'Tackles', 'value': '2'},\n",
      " 'tries': {'name': 'Tries', 'value': '0'},\n",
      " 'tryassists': {'name': 'Try Assists', 'value': '0'},\n",
      " 'turnoversconceded': {'name': 'Turnovers Conceded', 'value': '0'},\n",
      " 'url': 'http://en.espn.co.uk/sport/rugby/player/82104.html',\n",
      " 'wasActive': True,\n",
      " 'yellowcards': {'name': 'Yellow Cards', 'value': '0'}}\n"
     ]
    }
   ],
   "source": [
    "vals = ['name', 'cleanbreaks']\n",
    "data = stat_out[0][\"gamePackage\"][\"matchLineUp\"][\"home\"][\"team\"]\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query to create the table in MySQL - this will need a match and player identifier\n",
    "sql = \"\"\"drop table if exists scraping.p_stats;\n",
    "        create table p_stats( row_nk varchar(50) not null\n",
    "                            , player_id bigint(7) not null\n",
    "                            , match_id varchar(20) not null\n",
    "                            , match_date varchar(20)\n",
    "                            , name varchar(200)\n",
    "                            , number varchar(10)\n",
    "                            , position varchar(10)\n",
    "                            , captain varchar(10)\n",
    "                            , subbed varchar(10)\n",
    "                            , homeAway varchar(10)\n",
    "                            , subToolTip varchar(10)\n",
    "                            , onPitch varchar(10)\n",
    "                            , wasActive varchar(10)\n",
    "                            , tries bigint(7)\n",
    "                            , tryassists bigint(7)\n",
    "                            , points bigint(7)\n",
    "                            , kicks bigint(7)\n",
    "                            , passes bigint(7)\n",
    "                            , runs bigint(7)\n",
    "                            , metres bigint(7)\n",
    "                            , cleanbreaks bigint(7)\n",
    "                            , defendersbeaten bigint(7)\n",
    "                            , offload bigint(7)\n",
    "                            , lineoutwonsteal bigint(7)\n",
    "                            , turnoversconceded bigint(7)\n",
    "                            , tackles bigint(7)\n",
    "                            , missedtackles bigint(7)\n",
    "                            , lineoutswon bigint(7)\n",
    "                            , penaltiesconceded bigint(7)\n",
    "                            , yellowcards bigint(7)\n",
    "                            , redcards bigint(7)\n",
    "                            , penalties bigint(7)\n",
    "                            , penaltygoals bigint(7)\n",
    "                            , conversiongoals bigint(7)\n",
    "                            , dropgoalsconverted bigint(7)\n",
    "                            , primary key(row_nk));\"\"\".replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert the data into the table\n",
    "\n",
    "# Set up the connection\n",
    "import pymysql\n",
    "conn = pymysql.connect(host = '127.0.0.1', port = 3306,\n",
    "                       user = 'root', passwd = '', db = 'mysql')\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"USE scraping\")\n",
    "cur.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InterfaceError",
     "evalue": "(0, '')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-064087e2f47e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mcur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"USE scraping\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[1;31m#cur.execute(sql)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\barne\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, args)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmogrify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_executed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\barne\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_last_executed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrowcount\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\barne\\Anaconda3\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, sql, unbuffered)\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0msql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'surrogateescape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCOMMAND\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOM_QUERY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_affected_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_query_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_affected_rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\barne\\Anaconda3\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36m_execute_command\u001b[0;34m(self, command, sql)\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_execute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInterfaceError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"(0, '')\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[1;31m# If the last query was unbuffered, make sure it finishes before\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInterfaceError\u001b[0m: (0, '')"
     ]
    }
   ],
   "source": [
    "# attempt to do same for every player the match:\n",
    "# dct contains player data for a single game\n",
    "\n",
    "teams, players = ['home', 'away'], ['team', 'reserves']\n",
    "date = '20170304'\n",
    "\n",
    "for t in teams:\n",
    "    for p in players:\n",
    "        data = stat_out[0][\"gamePackage\"][\"matchLineUp\"][t][p]\n",
    "        \n",
    "        import re\n",
    "        #regex = re.compile('uniprotkb:P([0-9]*)')\n",
    "        regex = re.compile('gameId=([0-9]*)')\n",
    "        match_id = regex.findall(match_link)\n",
    "\n",
    "        for d in data:\n",
    "            dct = d\n",
    "            dct['match_date'] = date\n",
    "            dct['match_id'] = match_id[0] # regex above returns list of one element\n",
    "            if 'id' in dct:\n",
    "                dct['player_id'] = dct.pop('id') # rename 'id' to 'player_id'\n",
    "            dct['row_nk'] = dct['player_id'] + dct['match_id']\n",
    "            \n",
    "            # remove entries we don't want - url is useless and eventTimes doesn't conform to the required structure\n",
    "            # these are the keys, i.e. table column names\n",
    "            cols = list(dct.keys())\n",
    "            cols = list(filter(lambda c: c != 'eventTimes', cols))\n",
    "            cols = list(filter(lambda c: c != 'url', cols))\n",
    "\n",
    "            # these are used for the SQL query, so everything gets inserted at once\n",
    "            placeholders = ', '.join(['%s'] * len(cols))\n",
    "            columns = ', '.join(cols)\n",
    "\n",
    "            # These are the values to be inserted into the table\n",
    "            vals = []\n",
    "            for d in dct:\n",
    "                if d in cols:\n",
    "                    if type(dct[d]) is dict:\n",
    "                        vals.append(dct[d]['value'])\n",
    "                    else:\n",
    "                        vals.append(dct[d])\n",
    "\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(\"USE scraping\")\n",
    "            #cur.execute(sql)\n",
    "\n",
    "            sql_update = \"insert into p_stats (%s) values (%s)\" % (columns, placeholders)\n",
    "            cur.execute(sql_update, vals)\n",
    "            conn.commit()\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this first to set up connection drop the table, and create again before putting more data into it\n",
    "\n",
    "# Set up the connection\n",
    "import pymysql\n",
    "conn = pymysql.connect(host = '127.0.0.1', port = 3306,\n",
    "                       user = 'root', passwd = '', db = 'mysql')\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"USE scraping\")\n",
    "cur.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now try to do it for every match on a given date:\n",
    "# The list 'matches' contains 15 links for different games - try read all into DB\n",
    "\n",
    "\n",
    "# New function, very similar to the above, to extract the stats links\n",
    "def getStatsLinks (articleUrl):\n",
    "    html = urlopen(\"http://www.espn.co.uk\" + articleUrl)\n",
    "    bsObj = bs(html, \"lxml\")\n",
    "    return bsObj.find(\"section\", {\"id\":\"pane-main\"}).findAll(\"script\", {\"type\":\"text/javascript\"})\n",
    "\n",
    "def getStats(statsUrl):\n",
    "    html = urlopen(\"http://www.espn.co.uk\" + statsUrl)\n",
    "    bsObj = bs(html, \"lxml\")  \n",
    "    return bsObj.find(\"section\", {\"id\":\"pane-main\"}).findAll(\"script\", {\"type\":\"text/javascript\"})\n",
    "\n",
    "teams, players = ['home', 'away'], ['team', 'reserves']\n",
    "date = '20170304'\n",
    "\n",
    "# Iterate through all the matches on a given day and pull the data\n",
    "for match_link in matches:\n",
    "    tst = getStatsLinks(match_link)\n",
    "    json_out = []\n",
    "    for t in tst:\n",
    "        json_text = re.search(r'^\\s*window\\.__INITIAL_STATE__\\s*=\\s*({.*?})\\s*;\\s*$',\n",
    "                          t.string, flags=re.DOTALL | re.MULTILINE).group(1)\n",
    "        json_out.append(json.loads(json_text))\n",
    "        \n",
    "    for j in json_out[0]['gamePackage']['links']:\n",
    "        if j['pageType'] == 'matchstats':\n",
    "            match_s = j['href']\n",
    "        elif j['pageType'] == 'playerstats':\n",
    "            player_s = j['href']\n",
    "            \n",
    "    # Use regex to extract the match ID from the link\n",
    "    import re\n",
    "    regex = re.compile('gameId=([0-9]*)')\n",
    "    match_id = regex.findall(match_link)\n",
    "    \n",
    "    p_stats = getStats(player_s)\n",
    "\n",
    "    # json.loads turns the JSON object into a Python dict - so it's now a dict and follows those rules \n",
    "    stat_out = []\n",
    "    # This is length 1 but has to be done as if we don't iterate though it's of type \"ResultsSet\"\n",
    "    # which we can do do any operations on. So after this it will take the __INITIAL_STATE__ variable,\n",
    "    # grab the JSON object and make it into a Python dict\n",
    "    for p in p_stats:\n",
    "        json_text = re.search(r'^\\s*window\\.__INITIAL_STATE__\\s*=\\s*({.*?})\\s*;\\s*$',\n",
    "                          t.string, flags=re.DOTALL | re.MULTILINE).group(1)\n",
    "        stat_out.append(json.loads(json_text))\n",
    "        \n",
    "    for t in teams:\n",
    "        for p in players:\n",
    "            data = stat_out[0][\"gamePackage\"][\"matchLineUp\"][t][p]\n",
    "            \n",
    "\n",
    "            for d in data:\n",
    "                dct = d\n",
    "                \n",
    "                dct['match_date'] = date\n",
    "                dct['match_id'] = match_id[0] # regex above returns list of one element\n",
    "                if 'id' in dct:\n",
    "                    dct['player_id'] = dct.pop('id') # rename 'id' to 'player_id'\n",
    "                dct['row_nk'] = dct['player_id'] + dct['match_id']\n",
    "\n",
    "                # remove entries we don't want - url is useless and eventTimes doesn't conform to the required structure\n",
    "                # these are the keys, i.e. table column names\n",
    "                cols = list(dct.keys())\n",
    "                cols = list(filter(lambda c: c != 'eventTimes', cols))\n",
    "                cols = list(filter(lambda c: c != 'url', cols))\n",
    "\n",
    "                # these are used for the SQL query, so everything gets inserted at once\n",
    "                placeholders = ', '.join(['%s'] * len(cols))\n",
    "                columns = ', '.join(cols)\n",
    "\n",
    "                # These are the values to be inserted into the table\n",
    "                vals = []\n",
    "                for d in dct:\n",
    "                    if d in cols:\n",
    "                        if type(dct[d]) is dict:\n",
    "                            vals.append(dct[d]['value'])\n",
    "                        else:\n",
    "                            vals.append(dct[d])\n",
    "\n",
    "                cur = conn.cursor()\n",
    "                cur.execute(\"USE scraping\")\n",
    "                #cur.execute(sql)\n",
    "\n",
    "                sql_update = \"insert into p_stats (%s) values (%s)\" % (columns, placeholders)\n",
    "                cur.execute(sql_update, vals)\n",
    "                conn.commit()\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gameStrip\n",
      "gameState\n",
      "meta\n",
      "headToHead\n",
      "gameStateClass\n",
      "matchSummary\n",
      "news\n",
      "leagueUid\n",
      "matchCommentary\n",
      "polling\n",
      "matchAttacking\n",
      "analytics\n",
      "matchHomeForm\n",
      "matchAwayForm\n",
      "matchStats\n",
      "links\n",
      "loading\n",
      "matchGlossary\n",
      "matchLineUp\n",
      "matchDefending\n",
      "showGameDetailFooter\n",
      "article\n",
      "matchEvents\n",
      "matchDiscipline\n",
      "commentaryFeedback\n",
      "matchConversation\n",
      "matchDetails\n",
      "standings\n",
      "HeadToHeadNode\n"
     ]
    }
   ],
   "source": [
    "for s in stat_out[0]['gamePackage']:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '04/03',\n",
      " 'gameState': 'final',\n",
      " 'header': 'Super Rugby 2017',\n",
      " 'network': '',\n",
      " 'target': '',\n",
      " 'teams': {'away': {'abbrev': 'CRUS',\n",
      "                    'color': 'FF0000',\n",
      "                    'href': '/rugby/team/_/id/25936/crusaders',\n",
      "                    'id': '25936',\n",
      "                    'logo': 'http://a1.espncdn.com/combiner/i?img=/i/teamlogos/rugby/teams/500/25936.png&h=42&w=42',\n",
      "                    'name': 'Crusaders',\n",
      "                    'overDetails': '',\n",
      "                    'record': '',\n",
      "                    'runDetails': '30',\n",
      "                    'score': '30',\n",
      "                    'scoreMarkup': '30',\n",
      "                    'scoreMarkupMobile': '30',\n",
      "                    'trackingName': '&lpos=rugby:game:game:clubhouse:team',\n",
      "                    'uid': 's:300~t:25936',\n",
      "                    'winner': True},\n",
      "           'home': {'abbrev': 'HLAND',\n",
      "                    'color': '000099',\n",
      "                    'href': '/rugby/team/_/id/25938/highlanders',\n",
      "                    'id': '25938',\n",
      "                    'logo': 'http://a1.espncdn.com/combiner/i?img=/i/teamlogos/rugby/teams/500/25938.png&h=42&w=42',\n",
      "                    'name': 'Highlanders',\n",
      "                    'overDetails': '',\n",
      "                    'record': '',\n",
      "                    'runDetails': '27',\n",
      "                    'score': '27',\n",
      "                    'scoreMarkup': '27',\n",
      "                    'scoreMarkupMobile': '27',\n",
      "                    'trackingName': '&lpos=rugby:game:game:clubhouse:team',\n",
      "                    'uid': 's:300~t:25938',\n",
      "                    'winner': False}},\n",
      " 'time': 'FT',\n",
      " 'winnerClass': 'team-b-winner',\n",
      " 'winnerClassMobile': 'cscore--away-winner'}\n"
     ]
    }
   ],
   "source": [
    "# Next step - find match details such as home and away team, date, and include\n",
    "from pprint import pprint\n",
    "pprint(stat_out[0]['gamePackage']['gameStrip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winnerClass\n",
      "network\n",
      "header\n",
      "winnerClassMobile\n",
      "target\n",
      "teams\n",
      "time\n",
      "gameState\n",
      "date\n"
     ]
    }
   ],
   "source": [
    "for g in stat_out[0]['gamePackage']['gameStrip']:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'ab'}\n"
     ]
    }
   ],
   "source": [
    "tst = {1:'a', 2:'b'}\n",
    "tst[3] = tst[1] + tst[2]\n",
    "print(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    dct = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'captain': False,\n",
       " 'cleanbreaks': {'name': 'Clean Breaks', 'value': '2'},\n",
       " 'conversiongoals': {'name': 'Conversion Goals', 'value': '0'},\n",
       " 'defendersbeaten': {'name': 'Defenders Beaten', 'value': '2'},\n",
       " 'dropgoalsconverted': {'name': 'Drop Goals Converted', 'value': '0'},\n",
       " 'eventTimes': {},\n",
       " 'homeAway': 'home',\n",
       " 'kicks': {'name': 'Kicks', 'value': '0'},\n",
       " 'lineoutswon': {'name': 'Lineouts Won', 'value': '0'},\n",
       " 'lineoutwonsteal': {'name': 'Lineout Won Steal', 'value': '0'},\n",
       " 'match_date': '20170304',\n",
       " 'match_id': ['290088'],\n",
       " 'metres': {'name': 'Metres Run', 'value': '61'},\n",
       " 'missedtackles': {'name': 'Missed Tackles', 'value': '2'},\n",
       " 'name': 'Taulupe Faletau',\n",
       " 'number': '8',\n",
       " 'offload': {'name': 'Offload', 'value': '0'},\n",
       " 'onPitch': True,\n",
       " 'passes': {'name': 'Passes', 'value': '8'},\n",
       " 'penalties': {'name': 'penalties', 'value': '0'},\n",
       " 'penaltiesconceded': {'name': 'Penalties Conceded', 'value': '1'},\n",
       " 'penaltygoals': {'name': 'Penalty Goals', 'value': '0'},\n",
       " 'player_id': '104729',\n",
       " 'points': {'name': 'Points', 'value': '0'},\n",
       " 'position': 'N8',\n",
       " 'redcards': {'name': 'Red Cards', 'value': '0'},\n",
       " 'runs': {'name': 'Runs', 'value': '6'},\n",
       " 'subToolTip': '',\n",
       " 'subbed': False,\n",
       " 'tackles': {'name': 'Tackles', 'value': '6'},\n",
       " 'tries': {'name': 'Tries', 'value': '0'},\n",
       " 'tryassists': {'name': 'Try Assists', 'value': '0'},\n",
       " 'turnoversconceded': {'name': 'Turnovers Conceded', 'value': '1'},\n",
       " 'url': 'http://en.espn.co.uk/sport/rugby/player/104729.html',\n",
       " 'wasActive': True,\n",
       " 'yellowcards': {'name': 'Yellow Cards', 'value': '0'}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
