{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rugby/report?gameId=290778&league=242041\n"
     ]
    }
   ],
   "source": [
    "# TEST - go to the scrum.com fixtures page and extract the results links. Info is in JSON format, so pull that \n",
    "# from the HTML then parse\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import datetime\n",
    "import random\n",
    "import re\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "\n",
    "# This works for pages that have a single match, probably not for multiple matches\n",
    "date = '20170302'\n",
    "def getLinks (articleUrl):\n",
    "    html = urlopen(\"http://www.espn.co.uk/rugby/fixtures/_/date/\" + articleUrl)\n",
    "    bsObj = bs(html, \"lxml\")\n",
    "    return bsObj.find(\"section\", {\"id\":\"pane-main\"}).findAll(\"script\", {\"type\":\"text/javascript\"})\n",
    "    return bsObj.find(\"section\", {\"id\":\"pane-main\"})\n",
    "\n",
    "\n",
    "tst = getLinks(date)\n",
    "for t in tst:\n",
    "    json_text = re.search(r'^\\s*window\\.__INITIAL_STATE__\\s*=\\s*({.*?})\\s*;\\s*$',\n",
    "                      t.string, flags=re.DOTALL | re.MULTILINE).group(1)\n",
    "\n",
    "json_out = json.loads(json_text)\n",
    "match = json_out['schedule']['groups'][0]['complete'][0]['result']['href']\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/rugby/report?gameId=290778&league=242041'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_out['schedule']['groups'][0]['complete'][0]['result']['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing a day with multiple matches\n",
    "# TEST - go to the scrum.com fixtures page and extract the results links. Info is in JSON format, so pull that \n",
    "# from the HTML then parse\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import datetime\n",
    "import random\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "\n",
    "# This works for pages that have a single match, probably not for multiple matches\n",
    "date = '20170304'\n",
    "def getLinks (articleUrl):\n",
    "    html = urlopen(\"http://www.espn.co.uk/rugby/fixtures/_/date/\" + articleUrl)\n",
    "    bsObj = bs(html, \"lxml\")\n",
    "    return bsObj.find(\"section\", {\"id\":\"pane-main\"}).findAll(\"script\", {\"type\":\"text/javascript\"})\n",
    "\n",
    "tst = getLinks(date)\n",
    "for t in tst:\n",
    "    json_text = re.search(r'^\\s*window\\.__INITIAL_STATE__\\s*=\\s*({.*?})\\s*;\\s*$',\n",
    "                      t.string, flags=re.DOTALL | re.MULTILINE).group(1)\n",
    "\n",
    "json_out = json.loads(json_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rugby/report?gameId=290088&league=267979\n",
      "/rugby/report?gameId=290089&league=267979\n",
      "/rugby/match?gameId=290364&league=270559\n",
      "/rugby/match?gameId=290363&league=270559\n",
      "/rugby/match?gameId=290366&league=270559\n",
      "/rugby/match?gameId=290365&league=270559\n",
      "/rugby/report?gameId=290524&league=270557\n",
      "/rugby/report?gameId=290520&league=270557\n",
      "/rugby/report?gameId=290523&league=270557\n",
      "/rugby/report?gameId=290786&league=242041\n",
      "/rugby/report?gameId=290785&league=242041\n",
      "/rugby/report?gameId=290784&league=242041\n",
      "/rugby/match?gameId=290783&league=242041\n",
      "/rugby/report?gameId=290782&league=242041\n",
      "/rugby/report?gameId=290781&league=242041\n"
     ]
    }
   ],
   "source": [
    "# Structure like so: json_out['schedule']['groups'][m]['complete'][n]['result']['href']\n",
    "# m is the league in question and n is the game within that league, iterate through both for all results\n",
    "\n",
    "json_match = json_out['schedule']['groups']\n",
    "matches = []\n",
    "\n",
    "for m in json_match:\n",
    "    for c in m['complete']:\n",
    "        matches.append(c['result']['href'])\n",
    "        \n",
    "for m in matches:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just pick a single match link to look at\n",
    "match_link = matches[0]\n",
    "\n",
    "# New function, very similar to the above, to extract the stats links\n",
    "def getStatsLinks (articleUrl):\n",
    "    html = urlopen(\"http://www.espn.co.uk\" + articleUrl)\n",
    "    bsObj = bs(html, \"lxml\")\n",
    "    return bsObj.find(\"section\", {\"id\":\"pane-main\"}).findAll(\"script\", {\"type\":\"text/javascript\"})\n",
    "\n",
    "# Saved to list this time but still only one element\n",
    "tst = getStatsLinks(match_link)\n",
    "json_out = []\n",
    "for t in tst:\n",
    "    json_text = re.search(r'^\\s*window\\.__INITIAL_STATE__\\s*=\\s*({.*?})\\s*;\\s*$',\n",
    "                      t.string, flags=re.DOTALL | re.MULTILINE).group(1)\n",
    "    json_out.append(json.loads(json_text))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are tall the match related links, we are interested in the match\n",
    "# and player stats, as well as lineups and possibly table\n",
    "json_out[0]['gamePackage']['links']\n",
    "\n",
    "for j in json_out[0]['gamePackage']['links']:\n",
    "    if j['pageType'] == 'matchstats':\n",
    "        match_s = j['href']\n",
    "    elif j['pageType'] == 'playerstats':\n",
    "        player_s = j['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getStats(statsUrl):\n",
    "    html = urlopen(\"http://www.espn.co.uk\" + statsUrl)\n",
    "    bsObj = bs(html, \"lxml\")  \n",
    "    return bsObj.find(\"section\", {\"id\":\"pane-main\"}).findAll(\"script\", {\"type\":\"text/javascript\"})\n",
    "\n",
    "p_stats = getStats(player_s)\n",
    "\n",
    "# json.loads turns the JSON object into a Python dict - so it's now a dict and follows those rules \n",
    "stat_out = []\n",
    "# This is length 1 but has to be done as if we don't iterate though it's of type \"ResultsSet\"\n",
    "# which we can do do any operations on. So after this it will take the __INITIAL_STATE__ variable,\n",
    "# grab the JSON object and make it into a Python dict\n",
    "for p in p_stats:\n",
    "    json_text = re.search(r'^\\s*window\\.__INITIAL_STATE__\\s*=\\s*({.*?})\\s*;\\s*$',\n",
    "                      t.string, flags=re.DOTALL | re.MULTILINE).group(1)\n",
    "    stat_out.append(json.loads(json_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for s in stat_out[0]:\n",
    "#    for i in stat_out[0][s]:\n",
    "#        print(s, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'captain': False,\n",
      " 'cleanbreaks': {'name': 'Clean Breaks', 'value': '0'},\n",
      " 'conversiongoals': {'name': 'Conversion Goals', 'value': '0'},\n",
      " 'defendersbeaten': {'name': 'Defenders Beaten', 'value': '0'},\n",
      " 'dropgoalsconverted': {'name': 'Drop Goals Converted', 'value': '0'},\n",
      " 'eventTimes': {'3': [\"41'+3\"]},\n",
      " 'homeAway': 'home',\n",
      " 'id': '82104',\n",
      " 'kicks': {'name': 'Kicks', 'value': '2'},\n",
      " 'lineoutswon': {'name': 'Lineouts Won', 'value': '0'},\n",
      " 'lineoutwonsteal': {'name': 'Lineout Won Steal', 'value': '0'},\n",
      " 'metres': {'name': 'Metres Run', 'value': '15'},\n",
      " 'missedtackles': {'name': 'Missed Tackles', 'value': '1'},\n",
      " 'name': 'Tom Homer',\n",
      " 'number': '15',\n",
      " 'offload': {'name': 'Offload', 'value': '0'},\n",
      " 'onPitch': False,\n",
      " 'passes': {'name': 'Passes', 'value': '6'},\n",
      " 'penalties': {'name': 'penalties', 'value': 1},\n",
      " 'penaltiesconceded': {'name': 'Penalties Conceded', 'value': '0'},\n",
      " 'penaltygoals': {'name': 'Penalty Goals', 'value': '1'},\n",
      " 'points': {'name': 'Points', 'value': '3'},\n",
      " 'position': 'FB',\n",
      " 'redcards': {'name': 'Red Cards', 'value': '0'},\n",
      " 'runs': {'name': 'Runs', 'value': '6'},\n",
      " 'subToolTip': '',\n",
      " 'subbed': False,\n",
      " 'tackles': {'name': 'Tackles', 'value': '2'},\n",
      " 'tries': {'name': 'Tries', 'value': '0'},\n",
      " 'tryassists': {'name': 'Try Assists', 'value': '0'},\n",
      " 'turnoversconceded': {'name': 'Turnovers Conceded', 'value': '0'},\n",
      " 'url': 'http://en.espn.co.uk/sport/rugby/player/82104.html',\n",
      " 'wasActive': True,\n",
      " 'yellowcards': {'name': 'Yellow Cards', 'value': '0'}}\n"
     ]
    }
   ],
   "source": [
    "vals = ['name', 'cleanbreaks']\n",
    "data = stat_out[0][\"gamePackage\"][\"matchLineUp\"][\"home\"][\"team\"]\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query to create the table in MySQL - this will need a match and player identifier\n",
    "sql = \"\"\"drop table if exists scraping.r_stats;\n",
    "        create table r_stats(id bigint(7) not null\n",
    "                            , name varchar(200)\n",
    "                            , number varchar(10)\n",
    "                            , position varchar(10)\n",
    "                            , captain varchar(10)\n",
    "                            , subbed varchar(10)\n",
    "                            , homeAway varchar(10)\n",
    "                            , subToolTip varchar(10)\n",
    "                            , onPitch varchar(10)\n",
    "                            , wasActive varchar(10)\n",
    "                            , tries bigint(7)\n",
    "                            , tryassists bigint(7)\n",
    "                            , points bigint(7)\n",
    "                            , kicks bigint(7)\n",
    "                            , passes bigint(7)\n",
    "                            , runs bigint(7)\n",
    "                            , metres bigint(7)\n",
    "                            , cleanbreaks bigint(7)\n",
    "                            , defendersbeaten bigint(7)\n",
    "                            , offload bigint(7)\n",
    "                            , lineoutwonsteal bigint(7)\n",
    "                            , turnoversconceded bigint(7)\n",
    "                            , tackles bigint(7)\n",
    "                            , missedtackles bigint(7)\n",
    "                            , lineoutswon bigint(7)\n",
    "                            , penaltiesconceded bigint(7)\n",
    "                            , yellowcards bigint(7)\n",
    "                            , redcards bigint(7)\n",
    "                            , penalties bigint(7)\n",
    "                            , penaltygoals bigint(7)\n",
    "                            , conversiongoals bigint(7)\n",
    "                            , dropgoalsconverted bigint(7)\n",
    "                            , primary key(id));\"\"\".replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert the data into the table\n",
    "\n",
    "# Set up the connection\n",
    "import pymysql\n",
    "conn = pymysql.connect(host = '127.0.0.1', port = 3306,\n",
    "                       user = 'root', passwd = '', db = 'mysql')\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"USE scraping\")\n",
    "cur.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# attempt to do same for every player the match:\n",
    "# dct contains player data for a single game\n",
    "\n",
    "teams, players = ['home', 'away'], ['team', 'reserves']\n",
    "\n",
    "for t in teams:\n",
    "    for p in players:\n",
    "        data = stat_out[0][\"gamePackage\"][\"matchLineUp\"][t][p]\n",
    "\n",
    "        for d in data:\n",
    "            dct = d\n",
    "\n",
    "            # remove entries we don't want - url is useless and eventTimes doesn't conform to the required structure\n",
    "            # these are the keys, i.e. table column names\n",
    "            cols = list(dct.keys())\n",
    "            cols = list(filter(lambda c: c != 'eventTimes', cols))\n",
    "            cols = list(filter(lambda c: c != 'url', cols))\n",
    "\n",
    "            # these are used for the SQL query, so everything gets inserted at once\n",
    "            placeholders = ', '.join(['%s'] * len(cols))\n",
    "            columns = ', '.join(cols)\n",
    "\n",
    "            # These are the values to be inserted into the table\n",
    "            vals = []\n",
    "            for d in dct:\n",
    "                if d in cols:\n",
    "                    if type(dct[d]) is dict:\n",
    "                        vals.append(dct[d]['value'])\n",
    "                    else:\n",
    "                        vals.append(dct[d])\n",
    "\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(\"USE scraping\")\n",
    "            #cur.execute(sql)\n",
    "\n",
    "            sql_update = \"insert into r_stats (%s) values (%s)\" % (columns, placeholders)\n",
    "            cur.execute(sql_update, vals)\n",
    "            conn.commit()\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this first to set up connection drop the table, and create again before putting more data into it\n",
    "\n",
    "# Set up the connection\n",
    "import pymysql\n",
    "conn = pymysql.connect(host = '127.0.0.1', port = 3306,\n",
    "                       user = 'root', passwd = '', db = 'mysql')\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"USE scraping\")\n",
    "cur.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now try to do it for every match on a given date:\n",
    "# The list 'matches' contains 15 links for different games - try read all into DB\n",
    "\n",
    "\n",
    "# New function, very similar to the above, to extract the stats links\n",
    "def getStatsLinks (articleUrl):\n",
    "    html = urlopen(\"http://www.espn.co.uk\" + articleUrl)\n",
    "    bsObj = bs(html, \"lxml\")\n",
    "    return bsObj.find(\"section\", {\"id\":\"pane-main\"}).findAll(\"script\", {\"type\":\"text/javascript\"})\n",
    "\n",
    "def getStats(statsUrl):\n",
    "    html = urlopen(\"http://www.espn.co.uk\" + statsUrl)\n",
    "    bsObj = bs(html, \"lxml\")  \n",
    "    return bsObj.find(\"section\", {\"id\":\"pane-main\"}).findAll(\"script\", {\"type\":\"text/javascript\"})\n",
    "\n",
    "teams, players = ['home', 'away'], ['team', 'reserves']\n",
    "\n",
    "\n",
    "# Iterate through all the matches on a given day and pull the data\n",
    "for match_link in matches:\n",
    "    tst = getStatsLinks(match_link)\n",
    "    json_out = []\n",
    "    for t in tst:\n",
    "        json_text = re.search(r'^\\s*window\\.__INITIAL_STATE__\\s*=\\s*({.*?})\\s*;\\s*$',\n",
    "                          t.string, flags=re.DOTALL | re.MULTILINE).group(1)\n",
    "        json_out.append(json.loads(json_text))\n",
    "        \n",
    "    for j in json_out[0]['gamePackage']['links']:\n",
    "        if j['pageType'] == 'matchstats':\n",
    "            match_s = j['href']\n",
    "        elif j['pageType'] == 'playerstats':\n",
    "            player_s = j['href']\n",
    "        \n",
    "    \n",
    "    p_stats = getStats(player_s)\n",
    "\n",
    "    # json.loads turns the JSON object into a Python dict - so it's now a dict and follows those rules \n",
    "    stat_out = []\n",
    "    # This is length 1 but has to be done as if we don't iterate though it's of type \"ResultsSet\"\n",
    "    # which we can do do any operations on. So after this it will take the __INITIAL_STATE__ variable,\n",
    "    # grab the JSON object and make it into a Python dict\n",
    "    for p in p_stats:\n",
    "        json_text = re.search(r'^\\s*window\\.__INITIAL_STATE__\\s*=\\s*({.*?})\\s*;\\s*$',\n",
    "                          t.string, flags=re.DOTALL | re.MULTILINE).group(1)\n",
    "        stat_out.append(json.loads(json_text))\n",
    "        \n",
    "    for t in teams:\n",
    "        for p in players:\n",
    "            data = stat_out[0][\"gamePackage\"][\"matchLineUp\"][t][p]\n",
    "\n",
    "            for d in data:\n",
    "                dct = d\n",
    "\n",
    "                # remove entries we don't want - url is useless and eventTimes doesn't conform to the required structure\n",
    "                # these are the keys, i.e. table column names\n",
    "                cols = list(dct.keys())\n",
    "                cols = list(filter(lambda c: c != 'eventTimes', cols))\n",
    "                cols = list(filter(lambda c: c != 'url', cols))\n",
    "\n",
    "                # these are used for the SQL query, so everything gets inserted at once\n",
    "                placeholders = ', '.join(['%s'] * len(cols))\n",
    "                columns = ', '.join(cols)\n",
    "\n",
    "                # These are the values to be inserted into the table\n",
    "                vals = []\n",
    "                for d in dct:\n",
    "                    if d in cols:\n",
    "                        if type(dct[d]) is dict:\n",
    "                            vals.append(dct[d]['value'])\n",
    "                        else:\n",
    "                            vals.append(dct[d])\n",
    "\n",
    "                cur = conn.cursor()\n",
    "                cur.execute(\"USE scraping\")\n",
    "                #cur.execute(sql)\n",
    "\n",
    "                sql_update = \"insert into r_stats (%s) values (%s)\" % (columns, placeholders)\n",
    "                cur.execute(sql_update, vals)\n",
    "                conn.commit()\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gameStrip\n",
      "gameState\n",
      "meta\n",
      "headToHead\n",
      "gameStateClass\n",
      "matchSummary\n",
      "news\n",
      "leagueUid\n",
      "matchCommentary\n",
      "polling\n",
      "matchAttacking\n",
      "analytics\n",
      "matchHomeForm\n",
      "matchAwayForm\n",
      "matchStats\n",
      "links\n",
      "loading\n",
      "matchGlossary\n",
      "matchLineUp\n",
      "matchDefending\n",
      "showGameDetailFooter\n",
      "article\n",
      "matchEvents\n",
      "matchDiscipline\n",
      "commentaryFeedback\n",
      "matchConversation\n",
      "matchDetails\n",
      "standings\n",
      "HeadToHeadNode\n"
     ]
    }
   ],
   "source": [
    "for s in stat_out[0]['gamePackage']:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '04/03',\n",
      " 'gameState': 'final',\n",
      " 'header': 'Super Rugby 2017',\n",
      " 'network': '',\n",
      " 'target': '',\n",
      " 'teams': {'away': {'abbrev': 'CRUS',\n",
      "                    'color': 'FF0000',\n",
      "                    'href': '/rugby/team/_/id/25936/crusaders',\n",
      "                    'id': '25936',\n",
      "                    'logo': 'http://a1.espncdn.com/combiner/i?img=/i/teamlogos/rugby/teams/500/25936.png&h=42&w=42',\n",
      "                    'name': 'Crusaders',\n",
      "                    'overDetails': '',\n",
      "                    'record': '',\n",
      "                    'runDetails': '30',\n",
      "                    'score': '30',\n",
      "                    'scoreMarkup': '30',\n",
      "                    'scoreMarkupMobile': '30',\n",
      "                    'trackingName': '&lpos=rugby:game:game:clubhouse:team',\n",
      "                    'uid': 's:300~t:25936',\n",
      "                    'winner': True},\n",
      "           'home': {'abbrev': 'HLAND',\n",
      "                    'color': '000099',\n",
      "                    'href': '/rugby/team/_/id/25938/highlanders',\n",
      "                    'id': '25938',\n",
      "                    'logo': 'http://a1.espncdn.com/combiner/i?img=/i/teamlogos/rugby/teams/500/25938.png&h=42&w=42',\n",
      "                    'name': 'Highlanders',\n",
      "                    'overDetails': '',\n",
      "                    'record': '',\n",
      "                    'runDetails': '27',\n",
      "                    'score': '27',\n",
      "                    'scoreMarkup': '27',\n",
      "                    'scoreMarkupMobile': '27',\n",
      "                    'trackingName': '&lpos=rugby:game:game:clubhouse:team',\n",
      "                    'uid': 's:300~t:25938',\n",
      "                    'winner': False}},\n",
      " 'time': 'FT',\n",
      " 'winnerClass': 'team-b-winner',\n",
      " 'winnerClassMobile': 'cscore--away-winner'}\n"
     ]
    }
   ],
   "source": [
    "# Next step - find match details such as home and away team, date, and include\n",
    "from pprint import pprint\n",
    "pprint(stat_out[0]['gamePackage']['gameStrip'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
